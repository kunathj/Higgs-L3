{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What happens in this notebook :-)\n",
    "\n",
    "* We read in MC samples for background and different signal models. We also read in the actual data from the L3 detector.\n",
    "\n",
    "* We train a BDT for a binary classification problem aiming to seperate signal from background.\n",
    "\n",
    "* Different checks such as generalization of the BDT on the test sample as well as the confusion matrix are shown.\n",
    "\n",
    "* We use the BDT response to place our cut, so we analyze efficiencies and purities for different cut positions.\n",
    "\n",
    "* The BDT is saved in a pickel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import plotting as pl\n",
    "import helpers\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/higgs_data.csv')\n",
    "\n",
    "higgs_85 = pd.read_csv('data/higgs_higgs_85.csv')\n",
    "higgs_90 = pd.read_csv('data/higgs_higgs_90.csv')\n",
    "higgs_95 = pd.read_csv('data/higgs_higgs_95.csv')\n",
    "eeqq = pd.read_csv('data/higgs_eeqq.csv')\n",
    "qq = pd.read_csv('data/higgs_qq.csv')\n",
    "wen = pd.read_csv('data/higgs_wen.csv')\n",
    "ww = pd.read_csv('data/higgs_ww.csv')\n",
    "zee = pd.read_csv('data/higgs_zee.csv')\n",
    "zz = pd.read_csv('data/higgs_zz.csv')\n",
    "\n",
    "\n",
    "framesMC_NoHiggs = [qq, ww, zz, zee, wen, eeqq]\n",
    "framesMC_NoHiggsNames = ['qq', 'ww', 'zz', 'zee', 'wen', 'eeqq']\n",
    "\n",
    "framesMC_HiggsModels = [higgs_85, higgs_90, higgs_95]\n",
    "framesMC_HiggsModelsNames = ['higgs_85', 'higgs_90', 'higgs_95']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{array}{|l||c|c|c|c|}\n",
    "\\hline\n",
    "\\textrm{sample name} & \\textrm{type of data} & \\textrm{real data} & \\textrm{No. of events} & \\sigma   [\\textrm{pb}] \\\\ \\hline\n",
    "\\textrm{higgs_qq} & q \\bar{q} & - & 200000 & 102 \\\\ \\hline\n",
    "\\textrm{higgs_ww} & W^+ W^- & - & 294500 & 16.5 \\\\ \\hline\n",
    "\\textrm{higgs_zz} & ZZ & - & 196000 & 0.975 \\\\ \\hline\n",
    "\\textrm{higgs_zee} & Z e^+ e^- & - & 29500 & 3.35 \\\\ \\hline\n",
    "\\textrm{higgs_wen} & q \\bar{q} e \\nu_e & - & 81786 & 2.90 \\\\ \\hline\n",
    "\\textrm{higgs_eeqq} & \\textrm{two photon coll} & - & 5940000 & 15600 \\\\ \\hline\n",
    "\\textrm{higgs_data} & \\textrm{data} & x & - & - \\\\ \\hline\n",
    "\\textrm{higgs_higgs_85} & \\textrm{Higgs} (m_{H} = 85 \\ \\textrm{GeV}) & - & 3972 & 0.0940\\\\ \\hline\n",
    "\\textrm{higgs_higgs_90} & \\textrm{Higgs} (m_{H} = 90 \\ \\textrm{GeV}) & - & 3973 & 0.0667\\\\ \\hline\n",
    "\\textrm{higgs_higgs_95} & \\textrm{Higgs} (m_{H} = 95 \\ \\textrm{GeV}) & - & 3971 & 0.0333\\\\ \\hline\t\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduce weights in order to rescale all the MC samples to the same luminosity\n",
    "\n",
    "per definition the weight of each measured event (data) is $1$. Thus, we want to rescale the MC to the same ntegrated Luminosity of the data taking which is $L = 176.773 \\ \\mathrm{pb}^{-1}$\n",
    "\n",
    "The weight for each MC sample is:\n",
    "$$ \n",
    "        \\mathrm{weight}_\\mathrm{MC} = L \\cdot  \\frac{\\sigma_\\mathrm{MC} }{N_\\mathrm{MC}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossSectionsMC_noHiggs = [102., 16.5, 0.975, 3.35, 2.9, 15600.]\n",
    "NumberMC_noHiggs = [200000., 294500., 196000., 29500., 81786., 5940000.]\n",
    "\n",
    "crossSectionsMC_HiggsModels = [0.094, 0.0667, 0.0333]\n",
    "NumberMC_HiggsModels = [3972., 3973., 3971.]\n",
    "\n",
    "\n",
    "Lum = 176.773\n",
    "\n",
    "\n",
    "weightsMC_noHiggs     = Lum*np.array(crossSectionsMC_noHiggs) / np.array(NumberMC_noHiggs) \n",
    "weightsMC_HiggsModels = Lum*np.array(crossSectionsMC_HiggsModels) / np.array(NumberMC_HiggsModels) \n",
    "\n",
    "\n",
    "#add column 'weight' to data frame of all bkg MC\n",
    "for i, frame in enumerate(framesMC_NoHiggs):\n",
    "    frame[\"weight\"] = weightsMC_noHiggs[i]\n",
    "    frame[\"class\"] = 0\n",
    "\n",
    "#add column 'weight' to data frame of all bkg+sig MC\n",
    "for i, frame in enumerate(framesMC_HiggsModels):\n",
    "    frame[\"weight\"] = weightsMC_HiggsModels[i]\n",
    "    frame[\"class\"] = 1\n",
    "    \n",
    "#add column 'weight'=1 to data \n",
    "data[\"weight\"] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick the Signal Model and produce data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signalModelindex = 0\n",
    "\n",
    "df_MC_noHiggs = pd.concat(framesMC_NoHiggs)\n",
    "df_MC_mH85 = framesMC_HiggsModels[signalModelindex]\n",
    "#merge bkg and sig MC\n",
    "df_mH85 = pd.concat([df_MC_noHiggs,df_MC_mH85])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform selection cut analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose only those columns which have some kinematical meaning and thus can be used for training\n",
    "df_MVA_mH85 = df_mH85[helpers.kinematical_vars + [\"class\", \"weight\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df_MVA_mH85.columns)\n",
    "\n",
    "print(len(df_MVA_mH85.columns)-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract target values\n",
    "# 0 <-> bkg\n",
    "# 1 <-> sig\n",
    "target = df_MVA_mH85['class']\n",
    "del df_MVA_mH85['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_MVA_mH85, target, \n",
    "                                                    stratify=target, \n",
    "                                                    random_state=42,\n",
    "                                                   train_size=0.65)\n",
    "X_train_w = X_train['weight']\n",
    "X_test_w = X_test['weight']\n",
    "\n",
    "\n",
    "print('No of train events', len(y_train))\n",
    "print('No of signal events',np.count_nonzero(y_train))\n",
    "print('fraction of bkg in training set',1 - 1.*np.count_nonzero(y_train) / len(y_train))\n",
    "\n",
    "print('-----------------------------')\n",
    "\n",
    "print('No of test events',len(y_test))\n",
    "print('No of signal events',np.count_nonzero(y_test))\n",
    "print('fraction of bkg in test set',1 - 1.*np.count_nonzero(y_test) / len(y_test))\n",
    "\n",
    "\n",
    "del X_train['weight']\n",
    "del X_test['weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grbcl = GradientBoostingClassifier(max_depth=3,random_state=0,learning_rate=0.01,n_estimators=300)#,n_estimators=100,learning_rate=0.3)\n",
    "grbcl.fit(X_train,y_train,sample_weight=X_train_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Training set score: {:.3f}\".format(grbcl.score(X_train, y_train,sample_weight=X_train_w)))\n",
    "print(\"Test set score: {:.3f}\".format(grbcl.score(X_test, y_test,sample_weight=X_test_w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importance = grbcl.feature_importances_\n",
    "feature = np.arange(len(X_train.columns))\n",
    "\n",
    "print(importance)\n",
    "print(importance.sum())\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.title(r\"feature importance ($m_\\mathrm{H} = 85$ GeV)\")\n",
    "plt.plot(feature,importance*100,'b*')\n",
    "plt.xticks(feature)\n",
    "ax.set_xticklabels(X_train.columns,rotation=90)\n",
    "plt.xlabel('features')\n",
    "plt.ylabel('feature importance [%]')\n",
    "#plt.savefig(\"./plots/feature_importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = grbcl.predict(X_test)\n",
    "\n",
    "\"\"\"import cPickle\n",
    "with open('BDT_85higgs.pkl', 'rb') as fid:\n",
    "    gnb_loaded = cPickle.load(fid)\n",
    "y_pred = gnb_loaded.predict(X_test)\n",
    "\"\"\"\n",
    "print(len(y_pred))\n",
    "print(len(y_test))\n",
    "\n",
    "cm = confusion_matrix(y_pred,y_test)#,labels=[\"bkg\",\"sig\"])\n",
    "cm = cm.T\n",
    "print(cm)\n",
    "\n",
    "cmap = plt.cm.Blues\n",
    "# normalize\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(2)\n",
    "classes = ['bkg','sig']\n",
    "plt.xticks(tick_marks, classes)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "\n",
    "\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, str(np.round(cm[i, j]*100,0))+' %',\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.title(r'Confusion Matrix ($m_\\mathrm{H}$ = 85 GeV)')\n",
    "plt.tight_layout()\n",
    "plt.ylabel('true category')\n",
    "plt.xlabel('predicted category')\n",
    "#plt.savefig(\"./plots/confusion_matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = X_train.copy()\n",
    "X_train_df['class'] = y_train\n",
    "\n",
    "X_test_df = X_test.copy()\n",
    "X_test_df['class'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bkg = X_train_df[X_train_df['class']==0]\n",
    "X_train_sig = X_train_df[X_train_df['class']==1]\n",
    "del X_train_bkg['class']\n",
    "del X_train_sig['class']\n",
    "\n",
    "X_test_bkg = X_test_df[X_test_df['class']==0]\n",
    "X_test_sig = X_test_df[X_test_df['class']==1]\n",
    "del X_test_bkg['class']\n",
    "del X_test_sig['class']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate test statistics on training set\n",
    "a_bkg = grbcl.decision_function(X_train_bkg)\n",
    "a_sig = grbcl.decision_function(X_train_sig)\n",
    "\n",
    "# evaluate test statistics on test set\n",
    "b_bkg = grbcl.decision_function(X_test_bkg)\n",
    "b_sig = grbcl.decision_function(X_test_sig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(a_bkg))\n",
    "binning = np.linspace(min(b_bkg),max(a_sig),30)\n",
    "binning = np.linspace(-8,5,30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binw = binning[1] - binning[0]\n",
    "\n",
    "N_a_bkg = np.histogram(a_bkg,bins=binning)[0]\n",
    "norm_a_bkg = 1.*len(a_bkg)\n",
    "N_a_sig = np.histogram(a_sig,bins=binning)[0]\n",
    "norm_a_sig = 1.*len(a_sig)\n",
    "\n",
    "plt.bar(binning[:-1], N_a_bkg/norm_a_bkg, width=binw, label='train bkg', alpha=0.5)\n",
    "plt.bar(binning[:-1], N_a_sig/norm_a_sig, width=binw, label='train sig', alpha=0.5)\n",
    "\n",
    "\n",
    "# test set part\n",
    "N_bkg = np.histogram(b_bkg,bins=binning)[0]\n",
    "norm_bkg = 1.*len(b_bkg)\n",
    "\n",
    "N_sig = np.histogram(b_sig,bins=binning)[0]\n",
    "norm_sig = 1.*len(b_sig)\n",
    "\n",
    "plt.errorbar(binning[:-1],N_bkg/norm_bkg,xerr=binw/2.,label='test bkg',\n",
    "            yerr=np.sqrt(N_bkg)/norm_bkg,fmt='.')\n",
    "plt.errorbar(binning[:-1],N_sig/norm_sig,xerr=binw/2.,label='test sig',\n",
    "            yerr=np.sqrt(N_sig)/norm_sig,fmt='.')\n",
    "            \n",
    "plt.ylabel(r'normalized event count: $\\frac{1}{N} \\, \\frac{\\mathrm{d} N}{\\mathrm{d}t}$ ')\n",
    "plt.xlabel(r'BDT response $t$ (decision function)')\n",
    "\n",
    "plt.legend()\n",
    "#plt.savefig(\"./plots/BDT_generalization_performance\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of events up to certain bin in t\n",
    "# of the BDT response\n",
    "sum_sig_cuts = []\n",
    "sum_bkg_cuts = []\n",
    "\n",
    "count = 0\n",
    "for s in N_sig :\n",
    "    count += s\n",
    "    sum_sig_cuts.append(count)\n",
    "\n",
    "count = 0\n",
    "for s in N_bkg :\n",
    "    count += s\n",
    "    sum_bkg_cuts.append(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(binning[:-1],1.*N_sig/(np.sqrt(N_sig + N_bkg + N_bkg)),'mo-',label='significance')\n",
    "#print(binning[:-1][np.argmax(1.*N_sig/(np.sqrt(N_sig + N_bkg + N_bkg)))])\n",
    "#plt.plot(np.sqrt(-2*(N_sig+N_bkg)*np.log(1+N_sig/N_bkg) + 2*N_sig),'ro--', label='lr significance')\n",
    "#plt.hlines(3.,0,30)\n",
    "#plt.vlines(14,0,7)\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "\n",
    "#plt.vlines(14,0,1)\n",
    "plt.plot(binning[:-1],1.-(np.array(sum_sig_cuts))/norm_sig,'co-',label='signal efficiency')\n",
    "plt.plot(binning[:-1],1.-(np.array(sum_bkg_cuts))/norm_bkg,'bo-',label='background efficiency')\n",
    "plt.plot(binning[:-1],1.*N_sig / (N_sig+N_bkg),'go-',label='signal purity')\n",
    "plt.plot(binning[:-1],(1.*N_sig / (N_sig+N_bkg))*(1.-(np.array(sum_sig_cuts))/norm_sig),'ro-',label='signal efficiency * purity')\n",
    "plt.legend()\n",
    "plt.ylabel('efficiency (purity)')\n",
    "plt.xlabel(r'BDT response $t$ (decision function)')\n",
    "plt.xlim(-6.655,2.31)\n",
    "\n",
    "#plt.savefig(\"./plots/BDT_eff_purity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the classifier\n",
    "with open('BDT_85higgs1.pkl', 'wb') as fid:\n",
    "    pickle.dump(grbcl, fid)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=2,random_state=0)\n",
    "tree.fit(X_train,y_train,sample_weight=X_train_w.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save tree\n",
    "export_graphviz(tree,out_file='tree.dot',class_names=['bkg','sig'],feature_names=X_train.columns,\n",
    "               impurity=False,filled=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open tree\n",
    "with open('tree.dot') as f :\n",
    "    dot_graph = f.read()\n",
    "graphviz.Source(dot_graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in order to convert .dot to ps use:\n",
    "\n",
    "dot -Tps tree.dot -o myTree.ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('Higgs-L3': conda)",
   "language": "python",
   "name": "python38564bithiggsl3conda141e2cf07ec6480bb46052f1e5673410"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
